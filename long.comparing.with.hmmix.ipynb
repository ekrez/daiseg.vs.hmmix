{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf9ccfd-e03c-4bc5-8e60-1ac63d97104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sims\n",
    "import numpy as np\n",
    "import msprime\n",
    "import pandas as pd\n",
    "\n",
    "import useful\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5222edba-8556-40ed-b457-5b9721bd67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation time, mutation rate and recomination rate\n",
    "RR = 1e-8\n",
    "MU = 1.29e-8 \n",
    "GEN_time = 29.0 \n",
    "\n",
    "# Split Times\n",
    "T_NEAND_migration = 55000 #time of Neanderthal migration into Out_of_africa population\n",
    "T_NEAND_AMH = 550000 # split time between AMH and Neanderthal\n",
    "T_OOF_AF = 65700 # Out_of_Africa migration time\n",
    "T_NEAND_samples = 38000\n",
    "\n",
    "# Effective population size\n",
    "N_ANC = 18500 # N_e of common  AMH and NEanderthal population \n",
    "N_ND = 3400 # N_e of Neanderthal\n",
    "N_AMH = 23000 # N_e of AMH\n",
    "N_OOF = 1861 # N_e of Out_of_Africa population\n",
    "N_AF = 27600 # N_e of Africans\n",
    "N_EU = 13377 #N_e of Europeans\n",
    "\n",
    "N_EU_bottleneck = 1080\n",
    "N_EU_growth = 1450\n",
    "T_EU_growth = 31900\n",
    "gr_rate = 0.00202\n",
    "Portion_admix = 0.03\n",
    "\n",
    "len_sequence = 200000000 # DNA sequence length\n",
    "\n",
    "n = 250 # number of generated   AF samples\n",
    "n_neand = 6 #number of generated Neanderthals\n",
    "\n",
    "rand_sd =1234 #random seed\n",
    "T = np.array([T_NEAND_migration, T_NEAND_AMH, T_OOF_AF])/GEN_time\n",
    "\n",
    "\n",
    "N_ND = 3400 # N_e of Neanderthal\n",
    "N_e = np.array([N_ANC, N_ND, N_AMH, N_OOF, N_AF, N_EU])\n",
    "\n",
    "n_eu=1\n",
    "ploidy=2\n",
    "L=1000\n",
    "N_ref_pop=250\n",
    "N_neanderthal=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc18a55-2fe9-4153-89ca-bca92ab99a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neand ancestry:  [0.02947789, 0.025385235]\n",
      "Neand ancestry:  [0.02621176, 0.02341772]\n",
      "Neand ancestry:  [0.033959455, 0.032411275]\n",
      "Neand ancestry:  [0.0213661, 0.02652531]\n",
      "Neand ancestry:  [0.04064614, 0.042716975]\n",
      "Done 0\n",
      "Done 1\n"
     ]
    }
   ],
   "source": [
    "number_chr=5\n",
    "ts_mas, ND_true_tracts_mas = sims.sim_history_archaic_many_ts(GEN_time, len_sequence, RR, MU, N_e, T,  n, rand_sd, n_neand,  \n",
    "                              T_NEAND_samples/GEN_time, n_eu, N_EU_growth, \n",
    "                              T_EU_growth/GEN_time, N_EU_bottleneck, gr_rate, Portion_admix, ploidy, number_chr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbbc54f-b0db-4f12-8620-80a7b15ba9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions that move the j-th set of tracts by j*len_sequence\n",
    "def many_in_one(nd_tracts_mas, number_chr):\n",
    "    nd2=[]\n",
    "    for _ in range(len(ts_mas)):\n",
    "        for j in range(len(nd_tracts_mas[_])):\n",
    "            nd2.append([nd_tracts_mas[_][j][0]+_*len_sequence, nd_tracts_mas[_][j][1]+_*len_sequence])\n",
    "\n",
    "    return [useful.tracts_eu(nd2, len_sequence*len(ts_mas) ), nd2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f3c7d-9f95-4c29-9f85-03d85b61fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_nd=[ND_true_tracts_mas[_][0] for _ in range(len(ts_mas))]  \n",
    "real_tracts_in_states = many_in_one(true_nd,number_chr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7be8c2-0abc-43b8-a721-2059d334be49",
   "metadata": {},
   "source": [
    "# DAIseg preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e999340-02a9-43bc-952a-2e1d0ee4e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_mas=[0.25,0.5, 0.75, 0.999]\n",
    "\n",
    "for cover in cover_mas:\n",
    "    for _ in range(len(ts_mas)):\n",
    "        sims.create_obs_txt_coverage('obs.chr'+str(_+1)+'.cover.'+str(cover)+'.txt', ploidy,  n_eu, ts_mas[_], N_ref_pop, N_neanderthal, n, cover)\n",
    "    sims.create_bed_smpls_arch_cov('samples.txt', 'test.bed','arch.cover.'+str(cover)+'.txt', len_sequence, cover, 1, n_eu, ploidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba70fa8-b78f-42cd-8032-ef828a967022",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./run.daiseg.long.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c067dc-e4f8-4bad-b874-e3cae1efb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_daiseg_mas=[]\n",
    "df_daiseg_mas=[]\n",
    "for cover in cover_mas:\n",
    "    daiseg=[]\n",
    "    for _ in range(number_chr):\n",
    "        daiseg.append(useful.read_out('out.chr'+str(_+1)+'.cover.'+str(cover)+'.archaic.txt')[0])\n",
    "    tracts_daiseg = many_in_one(daiseg, number_chr)\n",
    "    tracts_daiseg_mas.append(tracts_daiseg)\n",
    "    df_daiseg_mas.append(sims.df_result_lonf_chr(real_tracts_in_states, tracts_daiseg, N_neanderthal,  N_ref_pop, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311296f-84d8-404a-bda0-da2aedcdacc5",
   "metadata": {},
   "source": [
    "# HMMIX preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b4fb2c-c1e9-4070-9f6f-f04c4f07178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparation_to_hmmix (ancestral alleles, fasta, vcf)\n",
    "\n",
    "j_son={\"ingroup\":['tsk_'+str(_) for _ in range(0, n_eu)], \"outgroup\" : ['tsk_'+str(_) for _ in range(n_eu, n_eu+N_ref_pop)]}\n",
    "with open('individuals.json', 'w') as f:\n",
    "    json.dump(j_son, f)\n",
    "\n",
    "for _ in range(len(ts_mas)):\n",
    "    with open('ts.'+'chr'+str(_+1)+'.vcf', \"w\") as vcf_file:\n",
    "        ts_mas[_].write_vcf(vcf_file, contig_id=str(_+1))\n",
    "\n",
    "sims.make_ancestral_fasta('ancestral', ts_mas, len_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443593f0-17c3-47f4-8722-55e52064ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#then run ./hmmix.sh from hmmix directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee769bfb-d18d-4477-aafc-68e24c552152",
   "metadata": {},
   "outputs": [],
   "source": [
    "file='out.tsk_0.hap1.txt'\n",
    "hmmix_cut_off=[0.75, 0.85, 0.9, 0.95]\n",
    "hmmix_nd_mas = [sims.read_noND(file, _ , number_chr) for _ in hmmix_cut_off]\n",
    "\n",
    "\n",
    "#The goal of this cell in to make ONE big chr\n",
    "tracts_hmmix_mas = [many_in_one(hmmix_nd_mas[_], number_chr) for _ in range(len(hmmix_cut_off))]\n",
    "df_hmmix_mas = [sims.df_result_lonf_chr(real_tracts_in_states, tracts_hmmix_mas[_], N_neanderthal,  N_ref_pop, 2) for _ in range(len(hmmix_cut_off))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c735473-86c3-4e9f-a1f1-d018b14fe867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76768e6d-0867-49b8-8600-0bd9b7e3a9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c32827e-ff8a-4eba-93b3-6402ec9fa046",
   "metadata": {},
   "source": [
    "# Studying of mean length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22361a2d-ebd6-41d0-9672-1511a3d40b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds=[[0, 10],[10, 20], [20, 30], [30, 40], [40, 60], [60, 120], [120, 200], [200, 5000]]\n",
    "\n",
    "\n",
    "df=pd.DataFrame(columns=['CHR', 'POS','Marker', 'Length', 'Int_with_real', 'Int_count', '%Truth', 'Length_category'])\n",
    "tracts=[real_tracts_in_states[1]]+[tracts_hmmix_mas[_][1] for _ in range(len(hmmix_cut_off))]+[tracts_daiseg_mas[_][1] for _ in range(len(cover_mas))]\n",
    "markers=['real']+['hmmix_'+str(cut) for cut in hmmix_cut_off] + ['daiseg_'+str(cover) for cover in cover_mas]\n",
    "\n",
    "for _, m in zip(tracts, markers):  \n",
    "    for j in _:\n",
    "        #counting number of intersections        \n",
    "        k=0\n",
    "        for i in tracts[0]:\n",
    "            if useful.intersections([j], [i]):\n",
    "                k+=1\n",
    "        for b in bounds:            \n",
    "            if (j[1]-j[0]+1)/1000>=b[0] and (j[1]-j[0]+1)/1000<=b[1]:\n",
    "                length_cat=b                \n",
    "        if k==0:\n",
    "            df.loc[len(df)]=[int(j[1]//len_sequence)+1,j,m, (j[1]-j[0]+1)/1000, 0, k, 0, length_cat]\n",
    "        else:            \n",
    "            df.loc[len(df)]=[int(j[1]//len_sequence)+1,j,m, (j[1]-j[0]+1)/1000, 1, k, \n",
    "                             useful.len_tracts(useful.intersections([j], tracts[0]))/useful.len_tracts([j]), length_cat]\n",
    "\n",
    "\n",
    "#proportion of false-positive length    in all length and in class \n",
    "\n",
    "for cut in hmmix_cut_off:\n",
    "\n",
    "    print('The dosage of false positive length in all tract length ', \n",
    "          np.array(df[(df['Marker']=='hmmix_'+str(cut)) & (df['Int_count']==0)]['Length']).sum()/np.array(df[(df['Marker']=='hmmix_'+str(cut))]['Length']).sum())\n",
    "\n",
    "\n",
    "\n",
    "for cover in cover_mas:\n",
    "\n",
    "    print('The dosage of false positive length in all tract length ', \n",
    "          np.array(df[(df['Marker']=='daiseg_'+str(cover)) & (df['Int_count']==0)]['Length']).sum()/np.array(df[(df['Marker']=='daiseg_'+str(cover))]['Length']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a6d1a-a5a8-48d5-bac8-3ef2fdd70b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d977db-8e52-479d-9176-832af7965d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8216a894-1bd8-4f95-b6c0-29dd0ea87662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deviation of mean by chr\n",
    "\n",
    "x=[_ for _ in range(number_chr)]\n",
    "means=[]\n",
    "for m in markers:\n",
    "    d=df[df['Marker']==m][['CHR','Length']]    \n",
    "    means.append(np.array(d.groupby(['CHR']).mean()['Length']))\n",
    "    \n",
    "\n",
    "df_means=pd.DataFrame({'CHR':[_ for _ in range(number_chr)], 'real': means[0], 'hmmix_09':means[1], \n",
    "                       'hmmix_085':means[2],'daiseg': means[3] })\n",
    "\n",
    "plt.plot(x, [(x-y)/y for x,y in zip(df_means['hmmix_09'],df_means['real'])], label='hmmix_09')\n",
    "plt.plot(x, [(x-y)/y for x,y in zip(df_means['hmmix_085'],df_means['real'])], label='hmmix_085')\n",
    "plt.plot(x, [(x-y)/y for x,y in zip(df_means['daiseg'],df_means['real'])], label='daiseg')\n",
    "\n",
    "\n",
    "plt.ylabel('Deviation from the mean length divided by the mean')\n",
    "plt.xlabel('Simulations')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig('deviation.of.mean.eps', format='eps', transparent=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586aaaba-dafe-499d-8b25-dbda83950a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18aa8af-fb4a-4ac7-ac9d-1e31f06ab463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4798b-55e3-44e5-acfc-510675c4340c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa20406-0da6-40dd-be57-3fd6cea7ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10), sharey=True, sharex=True)\n",
    "fig.suptitle('Length distribution of tracts')\n",
    "sns.histplot(ax=axes[0][0], data=df[df['Marker']=='real'], x='Length', alpha=0.6, binwidth=10 ,  kde=True, color='orange')\n",
    "sns.histplot(ax=axes[0][1], data=df[df['Marker']=='hmmix_0.75'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "sns.histplot(ax=axes[0][2], data=df[df['Marker']=='hmmix_0.85'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "sns.histplot(ax=axes[1][0], data=df[df['Marker']=='hmmix_0.9'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "sns.histplot(ax=axes[1][1], data=df[df['Marker']=='hmmix_0.95'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "sns.histplot(ax=axes[1][2], data=df[df['Marker']=='daiseg_0.25'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "sns.histplot(ax=axes[2][0], data=df[df['Marker']=='daiseg_0.5'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "sns.histplot(ax=axes[2][1], data=df[df['Marker']=='daiseg_0.75'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "sns.histplot(ax=axes[2][2], data=df[df['Marker']=='daiseg_0.999'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "\n",
    "\n",
    "axes[0][0].set_title('Real')\n",
    "axes[0][1].set_title('HMMmix_0.75')\n",
    "axes[0][2].set_title('HMMmix_0.85')\n",
    "axes[1][0].set_title('HMMmix_0.9')\n",
    "axes[1][1].set_title('HMMmix_0.95')\n",
    "axes[1][2].set_title('DAIseg_0.25')\n",
    "axes[2][0].set_title('DAIseg_0.5')\n",
    "axes[2][1].set_title('DAIseg_0.75')\n",
    "axes[2][2].set_title('DAIseg_0.99')\n",
    "#plt.savefig('Length distribution.eps', format='eps', transparent=True)\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85129795-df5d-4505-9629-ebd5680eb46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3fdc3c-96a4-46c4-a1dc-ab802fcca808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab8406-efc1-4503-9c60-671e24797817",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for v in ts_mas[0].variants():\n",
    "    if k<10:\n",
    "        print(v.site.ancestral_state, v.site.position, set(v.genotypes[0:502]))\n",
    "        k+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f73e7f-8446-4bdd-9b8a-694ce6055f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86e81f-504a-49f3-86be-0924543920c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91115c40-c525-4b8f-9702-819a9b32d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a1a94-f2e6-4fb5-abb0-89e1317791a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
