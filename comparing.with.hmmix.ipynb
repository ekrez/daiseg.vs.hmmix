{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf9ccfd-e03c-4bc5-8e60-1ac63d97104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sims\n",
    "import numpy as np\n",
    "import msprime\n",
    "import pandas as pd\n",
    "\n",
    "import useful\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222edba-8556-40ed-b457-5b9721bd67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation time, mutation rate and recomination rate\n",
    "RR = 1e-8\n",
    "MU = 1.29e-8 \n",
    "GEN_time = 29.0 \n",
    "\n",
    "# Split Times\n",
    "T_NEAND_migration = 55000 #time of Neanderthal migration into Out_of_africa population\n",
    "T_NEAND_AMH = 550000 # split time between AMH and Neanderthal\n",
    "T_OOF_AF = 65700 # Out_of_Africa migration time\n",
    "T_NEAND_samples = 38000\n",
    "\n",
    "# Effective population size\n",
    "N_ANC = 18500 # N_e of common  AMH and NEanderthal population \n",
    "N_ND = 3400 # N_e of Neanderthal\n",
    "N_AMH = 23000 # N_e of AMH\n",
    "N_OOF = 1861 # N_e of Out_of_Africa population\n",
    "N_AF = 27600 # N_e of Africans\n",
    "N_EU = 13377 #N_e of Europeans\n",
    "\n",
    "N_EU_bottleneck = 1080\n",
    "N_EU_growth = 1450\n",
    "T_EU_growth = 31900\n",
    "gr_rate = 0.00202\n",
    "Portion_admix = 0.03\n",
    "\n",
    "len_sequence = 50000000 # DNA sequence length\n",
    "\n",
    "n = 250 # number of generated   AF samples\n",
    "n_neand = 6 #number of generated Neanderthals\n",
    "\n",
    "rand_sd =1234 #random seed\n",
    "T = np.array([T_NEAND_migration, T_NEAND_AMH, T_OOF_AF])/GEN_time\n",
    "\n",
    "\n",
    "N_ND = 3400 # N_e of Neanderthal\n",
    "N_e = np.array([N_ANC, N_ND, N_AMH, N_OOF, N_AF, N_EU])\n",
    "\n",
    "n_eu=1\n",
    "ploidy=2\n",
    "L=1000\n",
    "N_ref_pop=250\n",
    "N_neanderthal=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86e81f-504a-49f3-86be-0924543920c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91115c40-c525-4b8f-9702-819a9b32d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions that move the j-th set of tracts by j*len_sequence\n",
    "def many_in_one(nd_tracts_mas, number_chr, length):\n",
    "    nd2=[]\n",
    "    for _ in range(len(nd_tracts_mas)):\n",
    "        for j in range(len(nd_tracts_mas[_])):\n",
    "            nd2.append([nd_tracts_mas[_][j][0]+_*length, nd_tracts_mas[_][j][1]+_*length])\n",
    "\n",
    "    return [useful.tracts_eu(nd2, length*number_chr ), nd2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533340e7-daea-45b3-becb-9391f0201ccc",
   "metadata": {},
   "source": [
    "# Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279900a2-00d6-42ce-a29c-6c38adb21e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_chr=60\n",
    "length=50000000\n",
    "\n",
    "dir='./sims3/'\n",
    "#read real\n",
    "r=[]\n",
    "real_tracts=[]\n",
    "for j in range(1, number_chr+1):\n",
    "    a=str(np.load(dir+str(j)+'.ND_true_tracts.npy', allow_pickle= True))\n",
    "\n",
    "    if 'list' in a:\n",
    "\n",
    "    \n",
    "        b=str(a).strip().replace('list','')[4:-4].replace('])','').replace(' ([' ,'').split('\\n')\n",
    "        for jj in b[0].split('], ['):      \n",
    "            real_tracts.append([int(float(_))+(j-1)*length for _ in jj.replace('[','').replace(']','').split(', ')])\n",
    "            \n",
    "\n",
    "    else:\n",
    "        for jj in a[4:-4].split('\\n\\n')[0].replace(']','').replace('[','').split('\\n   '):\n",
    "            real_tracts.append([float(jj.strip().split(' ')[0])+(j-1)*length, float(jj.split(' ')[1])+(j-1)*length])\n",
    "real_tracts_in_states = [useful.exclude_gaps([[0, number_chr*length]], real_tracts),real_tracts]\n",
    "\n",
    "\n",
    "#read daiseg\n",
    "tracts_daiseg_mas=[]\n",
    "df_daiseg_mas=[]\n",
    "cover_mas=[0.25, 0.4, 0.5, 0.65, 0.8, 0.9, 0.999]\n",
    "#cover_mas=[0.25,  0.5,  0.8,  0.999]\n",
    "for cover in cover_mas:\n",
    "    daiseg=[]\n",
    "    for _ in range(number_chr):\n",
    "        daiseg.append(useful.read_out(dir+'out.chr'+str(_+1)+'.cover.'+str(cover)+'.archaic.txt')[0])\n",
    "    tracts_daiseg = many_in_one(daiseg, number_chr, length)\n",
    "    tracts_daiseg_mas.append(tracts_daiseg)\n",
    "\n",
    "    df_daiseg_mas.append(sims.df_result_lonf_chr(real_tracts_in_states, tracts_daiseg, N_neanderthal,  N_ref_pop, 2))\n",
    "\n",
    "\n",
    "\n",
    "# read hmmix_results\n",
    "df_hmmix, hmmix_mas=[],[]\n",
    "#read hmmix tracts\n",
    "cut_mas=[0.85, 0.9, 0.95]\n",
    "\n",
    "for cut in cut_mas:\n",
    "\n",
    "    hmmmix_tr=[[] for j in range(number_chr)]\n",
    "    for j in range(1, number_chr+1):\n",
    "        file=dir+'out.chr'+str(j)+'.hap1.txt'    \n",
    "        hmmmix_tr[j-1]=sims.read_noND2(file, cut )\n",
    "\n",
    "\n",
    "        \n",
    "    hmmix=many_in_one(hmmmix_tr,number_chr, length)\n",
    "    hmmix_mas.append(hmmix)\n",
    "    df_hmmix.append(sims.df_result_lonf_chr(real_tracts_in_states, hmmix, N_neanderthal,  N_ref_pop, 2))\n",
    "\n",
    "\n",
    "#create dataframe with results\n",
    "bounds=[[0, 10],[10,20],[20,40],[40, 60], [60, 100], [100, 5000]]\n",
    "labels=[i for i in range(len(bounds))]\n",
    "df=pd.DataFrame(columns=['CHR', 'POS','Marker', 'Length', 'Int_with_real', 'Int_count', '%Truth', 'Length_category'])\n",
    "tracts=[real_tracts_in_states[1]]+[hmmix_mas[_][1] for _ in range(len(cut_mas))]+[tracts_daiseg_mas[_][1] for _ in range(len(cover_mas))]\n",
    "markers=['real']+['hmmix_'+str(cut) for cut in cut_mas] + ['daiseg_'+str(cover) for cover in cover_mas]\n",
    "\n",
    "for _, m in zip(tracts, markers):  \n",
    "    for j in _:\n",
    "        #counting number of intersections        \n",
    "        k=0\n",
    "        for i in tracts[0]:\n",
    "            if useful.intersections([j], [i]):\n",
    "                k+=1\n",
    "        for b in bounds:            \n",
    "            if (j[1]-j[0]+1)/1000>=b[0] and (j[1]-j[0]+1)/1000<=b[1]:\n",
    "                length_cat=labels[bounds.index(b)]                \n",
    "        if k==0:\n",
    "            df.loc[len(df)]=[int(j[1]//length)+1,j,m, (j[1]-j[0]+1)/1000, 0, k, 0, length_cat]\n",
    "        else:            \n",
    "            df.loc[len(df)]=[int(j[1]//length)+1,j,m, (j[1]-j[0]+1)/1000, 1, k, \n",
    "                             useful.len_tracts(useful.intersections([j], tracts[0])), length_cat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8420044-0aad-4938-ac83-f402e2106138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion of false-positive length    in all length and in class \n",
    "\n",
    "for cut in cut_mas:\n",
    "\n",
    "    print('The dosage of false positive length in all tract length ', 'hmmix_'+str(cut),\n",
    "          np.array(df[(df['Marker']=='hmmix_'+str(cut)) & (df['Int_count']==0)]['Length']).sum()/np.array(df[(df['Marker']=='hmmix_'+str(cut))]['Length']).sum())\n",
    "\n",
    "\n",
    "\n",
    "for cover in cover_mas:\n",
    "\n",
    "    print('The dosage of false positive length in all tract length ', 'daiseg_'+str(cover), \n",
    "          np.array(df[(df['Marker']=='daiseg_'+str(cover)) & (df['Int_count']==0)]['Length']).sum()/np.array(df[(df['Marker']=='daiseg_'+str(cover))]['Length']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0a83c-f2bd-421f-b55d-a5ca5dd8a062",
   "metadata": {},
   "source": [
    "# Hist plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec5e2e-8418-4ac3-995d-229dd990273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9), sharey=True, sharex='all')\n",
    "#fig.suptitle('Length distribution of tracts')\n",
    "sns.histplot(ax=axes[0][0], data=df[df['Marker']=='real'], x='Length', alpha=0.6, binwidth=10 ,  kde=True, color='orange')\n",
    "sns.histplot(ax=axes[0][1], data=df[df['Marker']=='hmmix_0.85'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack', hue_order=[0,1]  )\n",
    "sns.histplot(ax=axes[0][2], data=df[df['Marker']=='hmmix_0.95'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "sns.histplot(ax=axes[1][0], data=df[df['Marker']=='daiseg_0.25'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "sns.histplot(ax=axes[1][1], data=df[df['Marker']=='daiseg_0.65'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "\n",
    "sns.histplot(ax=axes[1][2], data=df[df['Marker']=='daiseg_0.999'], x='Length', alpha=0.6, binwidth=10,  kde=True, hue='Int_with_real',multiple='stack')\n",
    "\n",
    "\n",
    "axes[0][0].set_title('Real')\n",
    "axes[0][1].set_title('HMMmix_0.85')\n",
    "axes[0][2].set_title('HMMmix_0.95')\n",
    "axes[1][0].set_title('DAIseg_0.25')\n",
    "\n",
    "axes[1][1].set_title('DAIseg_0.65')\n",
    "\n",
    "axes[1][2].set_title('DAIseg_1.0')\n",
    "plt.savefig('Length.distribution.eps', format='eps', transparent=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d542f-40db-4679-bb43-817e1141570f",
   "metadata": {},
   "source": [
    "# Deviation from mean tract length by chr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44b220-1934-49a3-ac7a-84c16062e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deviation of mean by chr\n",
    "\n",
    "x=[_ for _ in range(1,number_chr+1)]\n",
    "means={}\n",
    "for m in list(set(df['Marker'])):\n",
    "    d=df[df['Marker']==m][['CHR','Length']]    \n",
    "    means[m]=np.array(d.groupby(['CHR']).mean()['Length'])\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(5, 5))\n",
    "\n",
    "ax.plot(x, sorted([(x-y)/y for x,y in zip(means['daiseg_0.999'],means['real'])]), label='daiseg_1.0')\n",
    "ax.plot(x, sorted([(x-y)/y for x,y in zip(means['hmmix_0.9'],means['real'])]), label='hmmix_0.9')\n",
    "ax.plot(x, sorted([(x-y)/y for x,y in zip(means['daiseg_0.5'],means['real'])]), label='daiseg_0.5')\n",
    "ax.plot(x, sorted([(x-y)/y for x,y in zip(means['daiseg_0.8'],means['real'])]), label='daiseg_0.8')\n",
    "#plt.plot(x, [(x-y)/y for x,y in zip(df_means['daiseg'],df_means['real'])], label='daiseg')\n",
    "\n",
    "\n",
    "ax.set_ylabel('Deviation from the real mean length divided by the real mean')\n",
    "ax.set_xlabel(' CHR')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig('deviation.of.mean.eps', format='eps', transparent=True)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da60af3a-ede8-426d-8d78-a63c0078c320",
   "metadata": {},
   "source": [
    "# Precision/recall by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80cfb4-000e-4602-9893-be98a4bc720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_labels=['hmmix_'+str(0.9)]+['daiseg_'+str(_) for _ in cover_mas]\n",
    "\n",
    "precision=[]\n",
    "for _ in cover_labels:\n",
    "\n",
    "    df2=df[df['Marker']==_]   \n",
    "    df2.head()\n",
    "    s=[0 for j in range(len(bounds))]\n",
    "    for b in range(len(labels)):        \n",
    "        s[b]=(df2[df2['Length_category']==labels[b]]['%Truth'].sum())/(df2[df2['Length_category']==labels[b]]['Length'].sum()*1000)\n",
    "\n",
    "    precision.append(s)\n",
    "\n",
    "precision=np.array(precision)\n",
    "precision= precision.transpose() \n",
    "\n",
    "recall=[]\n",
    "df1=df[df['Marker']=='real']\n",
    "df2=[df[df['Marker']==j] for j in cover_labels]\n",
    "for l in labels:\n",
    "    length_cover=[0 for _ in cover_labels]\n",
    "    length_full=0\n",
    "    lc_m2=[]\n",
    "    for j in df1[df1['Length_category']==l]['POS']:     \n",
    "        length_full += j[1]- j[0]\n",
    "        for c in range(len(cover_labels) ):\n",
    "            df22=df2[c]        \n",
    "            for i in df22['POS']:\n",
    "                length_cover[c]+=useful.len_tracts(useful.intersections([j], [i]))\n",
    "\n",
    "    recall.append([length_cover[__]/length_full for __ in range(len(cover_labels))])\n",
    "    \n",
    "recall=np.array(recall)\n",
    "            \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True, sharex=True)\n",
    "for s, k in zip(['pr'], [1]):\n",
    "    for j, c in zip(range(len(bounds)), ['r', 'g', 'b', 'c', 'm', 'y', 'salmon']):        \n",
    "        axes[0].plot([0]+[_ for _ in cover_mas], precision[j],    markersize=1, label=str(bounds[j]))\n",
    "        axes[1].plot([0]+[_ for _ in cover_mas], recall[j],    markersize=1, label=str(bounds[j]))\n",
    "\n",
    "axes[0].set_xlabel(\"Portion of Neanderthal coverage\")\n",
    "axes[1].set_xlabel(\"Portion of Neanderthal coverage\")\n",
    "axes[0].set_ylabel('% of the truth in hmm ND tracts')\n",
    "axes[1].set_ylabel('% hmm ND tracts in real tracts')\n",
    "\n",
    "\n",
    "\n",
    "l, lines=[],[]\n",
    "for ax in fig.axes: \n",
    "    Line, Label = ax.get_legend_handles_labels() #\n",
    "\n",
    "    lines.extend(Line) \n",
    "    l.extend(Label) \n",
    "    \n",
    "    break    \n",
    "fig.legend(lines, l, loc='upper right') \n",
    "plt.savefig('Length.quality.eps', format='eps', transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcd90b2-ec13-43af-a8fb-82e3d54dbd6e",
   "metadata": {},
   "source": [
    "# Merged pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3a7a7-e5ae-4e88-8b43-3d593fd1d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[(df['Marker']=='real')]\n",
    "\n",
    "dist=40000\n",
    "pair_set=[] # set of neghboring real tracts\n",
    "for j in range(len(df2['POS'])-1):\n",
    "    if -df2['POS'][j][1]+df2['POS'][j+1][0] < dist :\n",
    "        pair_set.append([df2['POS'][j],df2['POS'][j+1] ])\n",
    "\n",
    "for l in ['hmmix_'+str(cut) for cut in cut_mas] + ['daiseg_'+str(cover) for cover in cover_mas]:\n",
    "    c=0\n",
    "    for ps in pair_set:\n",
    "        for j in df[df['Marker']==l]['POS']:            \n",
    "            if useful.intersections([ps[0]],[j])!=[] and useful.intersections([ps[1]],[j])!=[]:\n",
    "                c+=1\n",
    "\n",
    "    print('% of neighboring pairs that gluing together',l,round(c/len(pair_set),3))\n",
    "    \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
